{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
    "\n",
    "The `textFile` function returns data in strings. This should work fine for this lab.\n",
    "\n",
    "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
    "```\n",
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines() )\n",
    "```\n",
    "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
    "rddPatents = sc.textFile(\"apat63_99.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"CITING\",\"CITED\"',\n",
       " '3858241,956203',\n",
       " '3858241,1324234',\n",
       " '3858241,3398406',\n",
       " '3858241,3557384']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCitations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"',\n",
       " '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,',\n",
       " '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,',\n",
       " '3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,',\n",
       " '3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddPatents.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Lab4-RDD\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "CITATIONS_PATH = \"cite75_99.txt.gz\"   # produced by Make.txt\n",
    "PATENTS_PATH   = \"apat63_99.txt.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citations sample: ['\"CITING\",\"CITED\"', '3858241,956203', '3858241,1324234', '3858241,3398406', '3858241,3557384']\n",
      "Patents header: \"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"\n"
     ]
    }
   ],
   "source": [
    "rddCitations = sc.textFile(CITATIONS_PATH).cache()\n",
    "rddPatents   = sc.textFile(PATENTS_PATH).cache()\n",
    "\n",
    "print(\"Citations sample:\", rddCitations.take(5))\n",
    "print(\"Patents header:\", rddPatents.first())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patent_to_state sample: [('3070802', 'TX'), ('3070803', 'IL'), ('3070804', 'OH'), ('3070805', 'CA'), ('3070806', 'PA')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Grab header & indices\n",
    "pat_header = rddPatents.first()\n",
    "hdr = next(csv.reader([pat_header]))\n",
    "i_PATENT  = hdr.index(\"PATENT\")\n",
    "i_COUNTRY = hdr.index(\"COUNTRY\")\n",
    "i_POSTATE = hdr.index(\"POSTATE\")\n",
    "\n",
    "# Full rows keyed by patent id: (pid, full_row_list)\n",
    "patent_rows = (\n",
    "    rddPatents\n",
    "      .filter(lambda ln: ln != pat_header)\n",
    "      .map(lambda ln: next(csv.reader([ln])))          # parse CSV line safely\n",
    "      .map(lambda cols: (cols[i_PATENT], cols))        # (pid, full_row_list)\n",
    "      .cache()\n",
    ")\n",
    "\n",
    "# (pid -> state) for US patents with non-empty state\n",
    "def parse_pat_row(line: str):\n",
    "    if line == pat_header:\n",
    "        return None\n",
    "    c = next(csv.reader([line]))\n",
    "    pid  = c[i_PATENT]\n",
    "    country = (c[i_COUNTRY] or \"\").upper()\n",
    "    state   = (c[i_POSTATE] or \"\").upper()\n",
    "    if country == \"US\" and state != \"\":\n",
    "        return (pid, state)\n",
    "    return None\n",
    "\n",
    "patent_to_state = (\n",
    "    rddPatents\n",
    "      .map(parse_pat_row)\n",
    "      .filter(lambda x: x is not None)\n",
    "      .cache()\n",
    ")\n",
    "\n",
    "print(\"patent_to_state sample:\", patent_to_state.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cit_pairs sample: [('\"CITING\"', '\"CITED\"'), ('3858241', '956203'), ('3858241', '1324234'), ('3858241', '3398406'), ('3858241', '3557384')]\n"
     ]
    }
   ],
   "source": [
    "def parse_citation(line: str):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return None\n",
    "    parts = line.split(\",\") if \",\" in line else line.split()\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    return (parts[0], parts[1])   # (citing, cited)\n",
    "\n",
    "cit_pairs = (\n",
    "    rddCitations\n",
    "      .map(parse_citation)\n",
    "      .filter(lambda x: x is not None)\n",
    "      .cache()\n",
    ")\n",
    "\n",
    "print(\"cit_pairs sample:\", cit_pairs.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same_counts sample: [('4135224', 2), ('4219866', 1), ('4510175', 1), ('5011803', 2), ('5010317', 2)]\n"
     ]
    }
   ],
   "source": [
    "# 1) attach citing_state â†’ re-key by cited\n",
    "citing_with_state = (\n",
    "    cit_pairs\n",
    "      .join(patent_to_state)                              # (citing, (cited, citing_state))\n",
    "      .map(lambda kv: (kv[1][0], (kv[0], kv[1][1])))      # (cited, (citing, citing_state))\n",
    ")\n",
    "\n",
    "# 2) attach cited_state\n",
    "both_states = citing_with_state.join(patent_to_state)     # (cited, ((citing, citing_state), cited_state))\n",
    "\n",
    "# 3) keep only same-state edges and count per citing\n",
    "same_counts = (\n",
    "    both_states\n",
    "      .map(lambda kv: (kv[1][0][0], 1) if kv[1][0][1] == kv[1][1] else None)  # (citing, 1)\n",
    "      .filter(lambda x: x is not None)\n",
    "      .reduceByKey(lambda a, b: a + b)                    # (citing, SAME_STATE)\n",
    "      .cache()\n",
    ")\n",
    "\n",
    "print(\"same_counts sample:\", same_counts.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5959466|1999 |14515|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |159  |0       |1       |NULL   |0.6186  |NULL    |4.8868  |0.0455  |0.044   |NULL    |NULL    |125       |\n",
      "|5983822|1999 |14564|1998   |US     |TX     |569900  |2      |NULL  |114   |5  |55    |200  |0       |0.995   |NULL   |0.7201  |NULL    |12.45   |0       |0       |NULL    |NULL    |103       |\n",
      "|6008204|1999 |14606|1998   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |121  |0       |1       |NULL   |0.7415  |NULL    |5       |0.0085  |0.0083  |NULL    |NULL    |100       |\n",
      "|5952345|1999 |14501|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |118  |0       |1       |NULL   |0.7442  |NULL    |5.1102  |0       |0       |NULL    |NULL    |98        |\n",
      "|5958954|1999 |14515|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |116  |0       |1       |NULL   |0.7397  |NULL    |5.181   |0       |0       |NULL    |NULL    |96        |\n",
      "|5998655|1999 |14585|1998   |US     |CA     |NULL    |1      |NULL  |560   |1  |14    |114  |0       |1       |NULL   |0.7387  |NULL    |5.1667  |NULL    |NULL    |NULL    |NULL    |96        |\n",
      "|5936426|1999 |14466|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |178  |0       |1       |NULL   |0.58    |NULL    |11.2303 |0.0765  |0.073   |NULL    |NULL    |94        |\n",
      "|5739256|1998 |13983|1995   |US     |CA     |70060   |2      |15    |528   |1  |15    |453  |0       |1       |NULL   |0.8232  |NULL    |15.1104 |0.1124  |0.1082  |NULL    |NULL    |90        |\n",
      "|5913855|1999 |14417|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1       |NULL   |0.7403  |NULL    |8.3595  |0       |0       |NULL    |NULL    |90        |\n",
      "|5925042|1999 |14445|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1       |NULL   |0.7382  |NULL    |8.3471  |0       |0       |NULL    |NULL    |90        |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# schema: every original column is String, add SAME_STATE as Integer\n",
    "schema = StructType(\n",
    "    [StructField(c, StringType(), True) for c in hdr] +\n",
    "    [StructField(\"SAME_STATE\", IntegerType(), False)]\n",
    ")\n",
    "\n",
    "# build rows in the exact order of 'hdr', append SAME_STATE at the end\n",
    "data = []\n",
    "for pid, (full_row, same) in top10_full:          # from your previous collect()\n",
    "    vals = [(full_row[i] if i < len(full_row) and full_row[i] != \"\" else None)\n",
    "            for i in range(len(hdr))]\n",
    "    vals.append(int(same))\n",
    "    data.append(tuple(vals))\n",
    "\n",
    "df_top10 = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# show exactly like the PNG (sort by SAME_STATE desc, PATENT asc)\n",
    "(df_top10\n",
    "   .select(*hdr, \"SAME_STATE\")\n",
    "   .orderBy(F.desc(\"SAME_STATE\"), F.asc(\"PATENT\"))\n",
    "   .show(10, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
