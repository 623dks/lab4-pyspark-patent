{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   null|     BE|   null|    null|      1|  null|   269|  6|    69| null|       1|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070802| 1963| 1096|   null|     US|     TX|    null|      1|  null|     2|  6|    63| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070803| 1963| 1096|   null|     US|     IL|    null|      1|  null|     2|  6|    63| null|       9|    null| 0.3704|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070804| 1963| 1096|   null|     US|     OH|    null|      1|  null|     2|  6|    63| null|       3|    null| 0.6667|    null|    null|    null|    null|    null|    null|    null|\n",
      "|3070805| 1963| 1096|   null|     US|     CA|    null|      1|  null|     2|  6|    63| null|       1|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our analysis, we're going to subset the data since we (initially) only need the `PATENT` and `POSTATE` data. This will make it easier to read the output of the various joins we'll do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patState = patents.filter(patents.COUNTRY == 'US').select(['PATENT','POSTATE']).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to do our first join. We'll use [and inner join](http://www.sql-join.com/sql-join-types) because we only want entries where both the patent is in the database and it actually cites some other patent. Following that, we're going to the drop the `PATENT` column because we alredy have that information in the `CITING` column. We're also going to rename the `POSTATE` column to `CITING_STATE` because we're going to join this table again and at that time we would have two `POSTATE` columns -- better to disambiguate now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "byCiting = patState.join(citations,patState.PATENT==citations.CITING, how='inner')\\\n",
    "           .drop(\"PATENT\").withColumnRenamed('POSTATE', 'CITING_STATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `byCiting` dataframe should now having the `CITING_STATE` for the `CITING` column, and only for the patents that are in the patent database and in the citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-------+\n",
      "|CITING_STATE| CITING|  CITED|\n",
      "+------------+-------+-------+\n",
      "|          CA|3858258|1331793|\n",
      "|          CA|3858258|1540798|\n",
      "|          IN|3858560| 957631|\n",
      "|          MT|3858597|3675252|\n",
      "|          MT|3858597|3815160|\n",
      "+------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "byCiting.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do our second join on the patent data `PATENT` and the `CITED` column to determine the state for each cited patent. And, again, we rename columns etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "byCited = patState.join(byCiting, patState.PATENT == byCiting.CITED, how='inner')\\\n",
    "          .drop(\"PATENT\").withColumnRenamed('POSTATE', 'CITED_STATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-------+-------+\n",
      "|CITED_STATE|CITING_STATE| CITING|  CITED|\n",
      "+-----------+------------+-------+-------+\n",
      "|         MN|          NJ|4496943|3071753|\n",
      "|         MN|          TN|4345315|3071753|\n",
      "|         MN|          IL|4120573|3071753|\n",
      "|         MN|          NJ|3949375|3071753|\n",
      "|         MN|          NY|4271479|3071753|\n",
      "+-----------+------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "byCited.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can eliminate all rows of this table where the stated of the citing and cited patent aren't the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameState = byCited.filter( byCited.CITING_STATE == byCited.CITING_STATE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, are table contains multiple entries for each `CITING` patent where the `CITED` entry is in the same state. We can count up the `CITED` entries using the `groupBy` mechanism and then [use the aggreation operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct) to count up the number of `CITED`. The column name of the number of same state patents is ugly, so I rename it to `SAME_STATE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameStateCount = sameState.groupBy('CITING').agg({\"CITED\" : \"count\"})\\\n",
    "                .withColumnRenamed('count(CITED)', 'SAME_STATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| CITING|SAME_STATE|\n",
      "+-------+----------+\n",
      "|3858597|         2|\n",
      "|3859029|         2|\n",
      "|3859627|         5|\n",
      "|3860038|         3|\n",
      "|3860100|         3|\n",
      "+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sameStateCount.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to produce the new patent data by joining the \"same state\" count into the original patent data. This involves a *left join* because we want to retain all the patents, including those that don't have any `SAME_STATE` references. We also drop the `CITING` column because it duplicates the `PATENT` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPatentData = patents.join(sameStateCount, patents.PATENT==sameStateCount.CITING, how='left').drop('CITING').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|3070853| 1963| 1096|   null|     US|     FL|    null|      1|  null|    49|  5|    59| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|      null|\n",
      "|3071083| 1963| 1096|   null|     AT|   null|    null|      1|  null|   104|  5|    55| null|       3|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|      null|\n",
      "|3071452| 1963| 1096|   null|     BE|   null|    null|      3|  null|   252|  1|    19| null|       2|    null|    0.0|    null|    null|    null|    null|    null|    null|    null|      null|\n",
      "|3071635| 1963| 1096|   null|     US|     NJ|    null|      2|  null|   585|  1|    19| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|      null|\n",
      "|3071741| 1963| 1096|   null|     US|     NY|    null|      6|  null|   333|  2|    21| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|      null|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPatentData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now write out the data to a (collection of) CSV files. In my example, this produced ~200 files of data. I would not recommend storing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newPatentData.write.csv(\"patent-data-augmented.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the final output -- the 10 patents with the largest number of same-state citations. The only thing that is complex here is that the PySpark value of \"null\" complicates sorting by a numeric field -- thus, we filter out the null entries and then sort by the `SAME_STATE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5887243| 1999|14326|   1995|     US|     NY|  752434|      2|  null|   455|  2|    21|  745|       0|  0.9785|   null|  0.8195|    null| 16.9289|     0.0|     0.0|    null|    null|       524|\n",
      "|5795784| 1998|14109|   1996|     US|     TX|     735|      2|     3|   436|  1|    19|  770|       0|   0.987|   null|  0.8489|    null| 13.0312|  0.0274|  0.0234|    null|    null|       495|\n",
      "|5856194| 1999|14249|   1996|     US|     TX|     735|      2|  null|   436|  1|    19|  737|       1|  0.9878|    0.0|  0.8479|     1.0| 14.3161|  0.0255|  0.0217|     1.0|     1.0|       472|\n",
      "|5994152| 1999|14578|   1997|     US|     CA|  716850|      2|  null|   438|  4|    46|  430|       0|  0.9884|   null|   0.887|    null| 13.2953|  0.0051|  0.0047|    null|    null|       343|\n",
      "|5999972| 1999|14585|   1996|     US|     CA|  551495|      2|  null|   709|  2|    22|  352|       0|     1.0|   null|  0.8714|    null|  4.0398|  0.0117|  0.0114|    null|    null|       337|\n",
      "|5817744| 1998|14158|   1997|     US|     ID|   70060|      2|    13|   528|  1|    15|  469|       0|     1.0|   null|  0.8207|    null| 15.0043|  0.1106|  0.1066|    null|    null|       332|\n",
      "|5987245| 1999|14564|   1996|     US|     CA|  551495|      2|  null|   709|  2|    22|  341|       0|     1.0|   null|  0.8737|    null|  4.0587|  0.0121|  0.0117|    null|    null|       326|\n",
      "|5848246| 1998|14221|   1996|     US|     CA|  551495|      2|    24|   709|  2|    22|  337|       6|     1.0| 0.6667|  0.8726|     1.0|  3.0742|  0.0123|  0.0119|     0.0|     0.0|       324|\n",
      "|5739256| 1998|13983|   1995|     US|     CA|   70060|      2|    15|   528|  1|    15|  453|       0|     1.0|   null|  0.8232|    null| 15.1104|  0.1124|  0.1082|    null|    null|       322|\n",
      "|5618907| 1997|13612|   1995|     US|     CA|   70060|      2|     6|   528|  1|    15|  453|       0|     1.0|   null|  0.8248|    null| 14.1369|  0.1103|   0.106|    null|    null|       321|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPatentData.filter(newPatentData.SAME_STATE.isNotNull()).sort('SAME_STATE', ascending=False).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
