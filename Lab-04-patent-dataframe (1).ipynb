{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   NULL|     BE|   NULL|    NULL|      1|  NULL|   269|  6|    69| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070802| 1963| 1096|   NULL|     US|     TX|    NULL|      1|  NULL|     2|  6|    63| NULL|       0|    NULL|   NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070803| 1963| 1096|   NULL|     US|     IL|    NULL|      1|  NULL|     2|  6|    63| NULL|       9|    NULL| 0.3704|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070804| 1963| 1096|   NULL|     US|     OH|    NULL|      1|  NULL|     2|  6|    63| NULL|       3|    NULL| 0.6667|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070805| 1963| 1096|   NULL|     US|     CA|    NULL|      1|  NULL|     2|  6|    63| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING: ./apat63_99.txt.gz | ./cite75_99.txt.gz\n"
     ]
    }
   ],
   "source": [
    "# === Lab 4 — DataFrame solution (Top-10 SAME_STATE like instructor PNG) ===\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import glob\n",
    "\n",
    "spark = SparkSession.builder.appName(\"lab4-df\").getOrCreate()\n",
    "\n",
    "# --- locate files in current dir OR ./data (works with your Make.txt) ---\n",
    "def pick_one(pats):\n",
    "    for p in pats:\n",
    "        m = sorted(glob.glob(p))\n",
    "        if m: return m[0]\n",
    "    raise FileNotFoundError(pats)\n",
    "\n",
    "patents_path   = pick_one([\"./apat63_99.txt*\", \"./data/apat63_99.txt*\"])\n",
    "citations_path = pick_one([\"./cite75_99.txt*\", \"./data/cite75_99.txt*\", \"./data/acite75_99.txt*\"])\n",
    "print(\"USING:\", patents_path, \"|\", citations_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read patents (CSV with header) ---\n",
    "patents_raw = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"sep\", \",\")\n",
    "         .option(\"quote\", '\"').option(\"escape\", '\"')\n",
    "         .option(\"mode\", \"DROPMALFORMED\")\n",
    "         .csv(patents_path)\n",
    ").cache()\n",
    "\n",
    "# --- read citations (try comma CSV; fall back to whitespace split) ---\n",
    "try_csv = spark.read.option(\"header\",\"false\").option(\"sep\",\",\").csv(citations_path)\n",
    "if len(try_csv.columns) == 2:\n",
    "    citations_raw = try_csv.toDF(\"CITING\",\"CITED\")\n",
    "else:\n",
    "    txt = spark.read.text(citations_path)\n",
    "    citations_raw = (txt\n",
    "        .select(F.split(F.col(\"value\"), r\"\\s+\").alias(\"c\"))\n",
    "        .select(F.col(\"c\").getItem(0).alias(\"CITING\"),\n",
    "                F.col(\"c\").getItem(1).alias(\"CITED\"))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- minimal normalized tables ---\n",
    "# US patents with a real state → map: pid -> state\n",
    "pmap = (patents_raw\n",
    "    .select(F.col(\"PATENT\").cast(\"string\").alias(\"pid\"),\n",
    "            F.upper(F.trim(\"COUNTRY\")).alias(\"country\"),\n",
    "            F.upper(F.trim(\"POSTATE\")).alias(\"state\"))\n",
    "    .filter((F.col(\"country\")==\"US\") & F.col(\"state\").isNotNull() & (F.col(\"state\")!=\"\"))\n",
    ").cache()\n",
    "\n",
    "# citations as strings (distinct to be safe)\n",
    "edges = (citations_raw\n",
    "    .select(F.col(\"CITING\").cast(\"string\").alias(\"citing\"),\n",
    "            F.col(\"CITED\").cast(\"string\").alias(\"cited\"))\n",
    "    .distinct()\n",
    ").cache()\n",
    "\n",
    "# --- add states to both sides (inner joins so both states exist) ---\n",
    "lk_citing = F.broadcast(pmap.select(F.col(\"pid\").alias(\"citing_id\"),\n",
    "                                    F.col(\"state\").alias(\"citing_state\")))\n",
    "lk_cited  = F.broadcast(pmap.select(F.col(\"pid\").alias(\"cited_id\"),\n",
    "                                    F.col(\"state\").alias(\"cited_state\")))\n",
    "\n",
    "pairs = (edges\n",
    "    .join(lk_citing, F.col(\"citing\")==F.col(\"citing_id\"), \"inner\")\n",
    "    .join(lk_cited,  F.col(\"cited\")==F.col(\"cited_id\"),  \"inner\")\n",
    "    .select(\"citing\",\"cited\",\"citing_state\",\"cited_state\")\n",
    ").cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------+\n",
      "|citing |cited  |citing_state|cited_state|\n",
      "+-------+-------+------------+-----------+\n",
      "|3858260|3090973|IL          |TX         |\n",
      "|3858359|3691689|IN          |IN         |\n",
      "|3858623|3159530|NY          |WI         |\n",
      "|3858836|3361515|CA          |NY         |\n",
      "|3858950|3510182|OH          |CT         |\n",
      "|3858950|3748003|OH          |IN         |\n",
      "|3858955|3753023|NJ          |NJ         |\n",
      "|3859122|3464922|NC          |NJ         |\n",
      "|3859210|3575852|TX          |IL         |\n",
      "|3859249|3316330|NC          |IL         |\n",
      "+-------+-------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (nice for interview) show the 4-column intermediate\n",
    "pairs.show(10, truncate=False)\n",
    "\n",
    "# --- SAME_STATE per citing patent: sum of boolean (0/1) ---\n",
    "same_by_citing = (pairs\n",
    "    .withColumn(\"is_same\", (F.col(\"citing_state\")==F.col(\"cited_state\")).cast(\"int\"))\n",
    "    .groupBy(\"citing\").agg(F.sum(\"is_same\").alias(\"SAME_STATE\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5959466|1999 |14515|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |159  |0       |1       |NULL   |0.6186  |NULL    |4.8868  |0.0455  |0.044   |NULL    |NULL    |125       |\n",
      "|5983822|1999 |14564|1998   |US     |TX     |569900  |2      |NULL  |114   |5  |55    |200  |0       |0.995   |NULL   |0.7201  |NULL    |12.45   |0       |0       |NULL    |NULL    |103       |\n",
      "|6008204|1999 |14606|1998   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |121  |0       |1       |NULL   |0.7415  |NULL    |5       |0.0085  |0.0083  |NULL    |NULL    |100       |\n",
      "|5952345|1999 |14501|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |118  |0       |1       |NULL   |0.7442  |NULL    |5.1102  |0       |0       |NULL    |NULL    |98        |\n",
      "|5958954|1999 |14515|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |116  |0       |1       |NULL   |0.7397  |NULL    |5.181   |0       |0       |NULL    |NULL    |96        |\n",
      "|5998655|1999 |14585|1998   |US     |CA     |NULL    |1      |NULL  |560   |1  |14    |114  |0       |1       |NULL   |0.7387  |NULL    |5.1667  |NULL    |NULL    |NULL    |NULL    |96        |\n",
      "|5936426|1999 |14466|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |178  |0       |1       |NULL   |0.58    |NULL    |11.2303 |0.0765  |0.073   |NULL    |NULL    |94        |\n",
      "|5739256|1998 |13983|1995   |US     |CA     |70060   |2      |15    |528   |1  |15    |453  |0       |1       |NULL   |0.8232  |NULL    |15.1104 |0.1124  |0.1082  |NULL    |NULL    |90        |\n",
      "|5913855|1999 |14417|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1       |NULL   |0.7403  |NULL    |8.3595  |0       |0       |NULL    |NULL    |90        |\n",
      "|5925042|1999 |14445|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1       |NULL   |0.7382  |NULL    |8.3471  |0       |0       |NULL    |NULL    |90        |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- augment the full patent rows with SAME_STATE (left join; fill 0) ---\n",
    "patents_aug = (patents_raw\n",
    "    .withColumn(\"PATENT_s\", F.col(\"PATENT\").cast(\"string\"))\n",
    "    .join(same_by_citing, F.col(\"PATENT_s\")==F.col(\"citing\"), \"left\")\n",
    "    .drop(\"citing\",\"PATENT_s\")\n",
    "    .withColumn(\"SAME_STATE\", F.coalesce(F.col(\"SAME_STATE\"), F.lit(0)))\n",
    ").cache()\n",
    "\n",
    "# --- print Top-10 like the instructor PNG (all original cols + SAME_STATE) ---\n",
    "pat_cols = patents_raw.columns  # preserve original column order\n",
    "(patents_aug\n",
    "    .select(*[F.col(c) for c in pat_cols], F.col(\"SAME_STATE\"))\n",
    "    .orderBy(F.desc(\"SAME_STATE\"), F.asc(\"PATENT\"))\n",
    "    .show(10, truncate=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
